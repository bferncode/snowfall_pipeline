{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68acf050-bb90-44b7-b609-5e243de5c76c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9619f74-53d7-41c6-8f80-f67777ec9ff7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from modules.clients import SnotelClient, NWSClient\n",
    "from modules.database import upsert_to_delta, get_table_watermark\n",
    "from modules.transformer import generate_combined_forecast\n",
    "from config.settings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed58958e-3100-4ca2-b337-2b968a6a074a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Setup Parameters\n",
    "run_mode = \"full\"  # options: [\"incremental\", \"full\"]\n",
    "\n",
    "snotel = SnotelClient()\n",
    "nws = NWSClient()\n",
    "\n",
    "# 2. Determine Dates\n",
    "if run_mode == \"incremental\":\n",
    "    last_date = get_table_watermark(TBL_SNOW_OBS, \"date\")\n",
    "    start_date = (last_date).strftime('%Y-%m-%d') if last_date else \"2026-01-05\"\n",
    "    end_date = (pd.Timestamp.now() + pd.Timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "else:\n",
    "    start_date = \"2026-01-05\"\n",
    "    end_date = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Running in {run_mode} mode with dates: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49ad0012-e6ea-4375-8076-c4e37bc24ea8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Process Observations\n",
    "stations = spark.table(TBL_WEATHER_STATIONS).toPandas()\n",
    "stations = stations[:5]\n",
    "all_obs = []\n",
    "for _, row in stations.iterrows():\n",
    "    data = snotel.fetch_historical_data(row['site_id'], row['ntwk'], start_date, end_date)\n",
    "    if data is not None: \n",
    "        all_obs.append(data)\n",
    "\n",
    "if all_obs:\n",
    "    from modules.transformer import transform_historical_data\n",
    "    \n",
    "    # Combine raw dataframes\n",
    "    obs_df = pd.concat(all_obs)\n",
    "    \n",
    "    # Transform raw columns (Station Id -> site_id, etc.) to match Delta schema\n",
    "    # This addresses the [DELTA_MERGE_UNRESOLVED_EXPRESSION] error\n",
    "    clean_obs_df = transform_historical_data(obs_df)\n",
    "    \n",
    "    # Use 'date_hr' and 'site_id' as join keys for a more granular unique constraint\n",
    "    upsert_to_delta(clean_obs_df, TBL_SNOW_OBS, [\"date_hr\", \"site_id\"], mode=run_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3d9ae5d-d889-4718-b0cf-470e94d5642d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Process Forecasts (Always upsert/refresh)\n",
    "all_hourly = []\n",
    "all_snow_grid = []\n",
    "for _, row in stations.iterrows():\n",
    "    all_hourly.append(nws.get_hourly_forecast(row['lat'], row['lon']).assign(site_id=row['site_id']))\n",
    "    all_snow_grid.append(nws.get_snow_grid_data(row['lat'], row['lon']).assign(site_id=row['site_id']))\n",
    "\n",
    "upsert_to_delta(pd.concat(all_hourly), TBL_WEATHER_FCST, [\"startTime\", \"site_id\"], mode=\"overwrite\")\n",
    "upsert_to_delta(pd.concat(all_snow_grid), TBL_SNOW_FCST, [\"snow_start\", \"site_id\"], mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d34c80a-d2bb-4137-a302-87f82cd4caeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Aggregate (Efficient Spark Join)\n",
    "generate_combined_forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e111c932-5773-4dfd-8730-209148ca9c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select *\n",
    "from gold.weather.combined_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ac3db28-4f81-4626-be0d-8b9f0fd5b7b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(\"bronze.raw.weather_forecast\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "etl_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
